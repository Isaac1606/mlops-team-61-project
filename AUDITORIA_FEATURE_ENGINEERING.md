# üîç AUDITOR√çA EXHAUSTIVA: FEATURE ENGINEERING & TEMPORAL LEAKAGE

**Fecha:** 2025-01-12  
**Auditor:** Dr. ML-MLOps Elite Reviewer  
**Notebooks Auditados:**  
- `notebook.ipynb` (EDA & Feature Engineering)
- `02_modeling.ipynb` (Modelado & Evaluaci√≥n)

---

## üìä I. VERIFICACI√ìN DE TEMPORAL LEAKAGE - LAGS Y ROLLING MEANS

### ‚úÖ **VEREDICTO: C√ìDIGO ACTUAL ES CORRECTO (SIN LEAKAGE)**

#### Evidencia del C√≥digo Actual (Cell 64 de notebook.ipynb):

```python
# LAGS - CORRECTO ‚úÖ
OPTIMAL_LAGS = [1, 24, 48, 72, 168]
for target in ['cnt_transformed']:
    for lag in OPTIMAL_LAGS:
        df_features[f'{target}_lag_{lag}h'] = df_features[target].shift(lag)
        #                                                             ^^^^^^^^
        # ‚úÖ .shift(lag) usa valores PASADOS (t-lag)
        # Para timestamp t=100, lag=1 usa valor de t=99 (CORRECTO)

# ROLLING MEANS - CORRECTO ‚úÖ
ROLLING_WINDOWS = [3, 24, 72]
for target in ['cnt_transformed']:
    for window in ROLLING_WINDOWS:
        df_features[f'{target}_roll_mean_{window}h'] = (
            df_features[target].shift(1).rolling(window=window, min_periods=1).mean()
            #                   ^^^^^^^^
            # ‚úÖ .shift(1) ANTES de .rolling() asegura NO usar valor actual
            # Para t=100, window=3: usa promedio de [t-1, t-2, t-3] = [99, 98, 97] (CORRECTO)
        )
```

#### Verificaci√≥n Matem√°tica:

**Para un timestamp t=100 con lag=24:**
```
df['lag_24h'] = df['cnt'].shift(24)

Resultado:
  t=100 ‚Üí lag_24h usa valor de t=76  ‚úÖ PASADO
  t=101 ‚Üí lag_24h usa valor de t=77  ‚úÖ PASADO
```

**Para un timestamp t=100 con rolling_mean_3h:**
```
df['roll_mean_3h'] = df['cnt'].shift(1).rolling(3).mean()

Paso 1: shift(1)
  t=100 ‚Üí shifted_value = valor de t=99

Paso 2: rolling(3).mean() sobre la serie shifteada
  t=100 ‚Üí promedio de shifted[t-2:t+1] = [valor_t97, valor_t98, valor_t99] ‚úÖ PASADO

Resultado: NO usa informaci√≥n de t=100 ni futura
```

### üîç An√°lisis de Potenciales Problemas Sutiles

#### ‚ö†Ô∏è Problema Detectado 1: `min_periods=1` en Rolling Windows

**C√≥digo actual:**
```python
.rolling(window=window, min_periods=1).mean()
```

**Problema:**
- Los primeros registros del rolling mean se calculan con MENOS observaciones de las esperadas
- Ejemplo: `window=24` ‚Üí Los primeros 23 valores usan <24 observaciones

**¬øEs data leakage?** ‚ùå NO t√©cnicamente, pero reduce calidad del feature

**Soluci√≥n recomendada:**
```python
# Opci√≥n 1: Usar min_periods=window (m√°s estricto)
.rolling(window=window, min_periods=window).mean()
# ‚Üí Genera NaN en primeros (window-1) registros

# Opci√≥n 2: Usar min_periods=window//2 (balanceado)
.rolling(window=window, min_periods=window//2).mean()
# ‚Üí Requiere al menos 50% de las observaciones esperadas
```

**Impacto:** BAJO - Los registros con NaN se eliminan despu√©s con `dropna()`

**Recomendaci√≥n:** Cambiar a `min_periods=window` para mayor consistencia

---

#### ‚ö†Ô∏è Problema Detectado 2: Cambios Porcentuales Sin Shift

**C√≥digo actual:**
```python
df_features['cnt_pct_change_1h'] = df_features['cnt_transformed'].pct_change(periods=1)
```

**¬øEs data leakage?** ‚ùå NO

**Explicaci√≥n:**
```python
pct_change(periods=1) calcula: (valor_t - valor_t-1) / valor_t-1

Para t=100:
  pct_change = (cnt[100] - cnt[99]) / cnt[99]
  
¬øUsa informaci√≥n futura? NO
¬øUsa valor actual (t=100)? S√ç, pero eso est√° permitido

ANALOG√çA: Es como usar 'temp' o 'hr' actuales - son observables en el momento t
```

**Veredicto:** CORRECTO ‚úÖ

---

## üö® II. PROBLEMAS CR√çTICOS DETECTADOS EN MODELADO

### ‚ùå **PROBLEMA 1: OVERFITTING SEVERO EN XGBOOST**

#### Evidencia:

```python
# M√©tricas en 02_modeling.ipynb (Cell 34 output)
Train RMSE: 5.05    ‚Üê SOSPECHOSAMENTE PERFECTO
Train R¬≤: 0.9998    ‚Üê 99.98% varianza explicada üö©üö©üö©

Validation RMSE: 42.88   ‚Üê Excelente (pero...)
Validation R¬≤: 0.9708    ‚Üê 97% 

# PERO... Cross-Validation (Cell 38 output)
CV RMSE: 138.40 ¬± 39.80  ‚Üê 3.2x PEOR que single split! üö©üö©üö©
CV R¬≤: 0.7277 ¬± 0.1960   ‚Üê Mucha variabilidad

# Discrepancia: 223% entre Val RMSE (single) y CV RMSE
# Ratio: 138.40 / 42.88 = 3.23x
```

#### Diagn√≥stico:

1. **Train R¬≤ = 0.9998** ‚Üí Modelo MEMORIZ√ì los datos (overfitting extremo)
2. **Val RMSE (42.88) << CV RMSE (138.40)** ‚Üí Validation set es "afortunado" (no representativo)
3. **Alta variabilidad en CV** (std=39.80) ‚Üí Modelo NO generaliza consistentemente

#### Causa Ra√≠z:

**Hiperpar√°metros demasiado permisivos:**
```python
# Cell 34 - XGBoost params ACTUALES
xgb_params = {
    'max_depth': 6,           # ‚Üê DEMASIADO profundo
    'learning_rate': 0.05,    # ‚Üê OK
    'min_child_weight': 3,    # ‚Üê POCO restrictivo
    'gamma': 0.1,             # ‚Üê Penalizaci√≥n MUY baja
    'reg_alpha': 0.1,         # ‚Üê L1 regularizaci√≥n BAJA
    'reg_lambda': 1.0,        # ‚Üê L2 regularizaci√≥n BAJA
    'subsample': 0.8,
    'colsample_bytree': 0.8,
}
```

#### ‚úÖ Soluci√≥n Propuesta:

```python
# HIPERPAR√ÅMETROS CORREGIDOS (M√ÅS CONSERVADORES)
xgb_params = {
    'n_estimators': 300,         # ‚Üì Reducido de 500
    'max_depth': 4,              # ‚Üì Reducido de 6 ‚Üí menos complejidad
    'learning_rate': 0.03,       # ‚Üì Reducido de 0.05 ‚Üí aprendizaje m√°s lento
    'subsample': 0.7,            # ‚Üì Reducido de 0.8 ‚Üí bootstrap m√°s agresivo
    'colsample_bytree': 0.7,     # ‚Üì Reducido de 0.8 ‚Üí menos features por √°rbol
    'colsample_bylevel': 0.7,    # ‚Üì Reducido de 0.8
    'min_child_weight': 5,       # ‚Üë Aumentado de 3 ‚Üí m√°s restrictivo
    'gamma': 0.5,                # ‚Üë Aumentado de 0.1 ‚Üí penalizaci√≥n moderada
    'reg_alpha': 0.5,            # ‚Üë Aumentado de 0.1 ‚Üí L1 m√°s fuerte
    'reg_lambda': 2.0,           # ‚Üë Aumentado de 1.0 ‚Üí L2 m√°s fuerte
    'random_state': 42,
    'n_jobs': -1,
    'tree_method': 'hist',
    'eval_metric': 'rmse',
    'early_stopping_rounds': 50
}
```

**Justificaci√≥n de cambios:**
- **max_depth‚Üì 6‚Üí4:** √Årboles m√°s shallow ‚Üí menos overfitting
- **learning_rate‚Üì 0.05‚Üí0.03:** Aprendizaje m√°s conservador ‚Üí mejor generalizaci√≥n
- **min_child_weight‚Üë 3‚Üí5:** Requiere m√°s muestras por hoja ‚Üí menos overfitting
- **gamma‚Üë 0.1‚Üí0.5:** Mayor penalizaci√≥n por splits ‚Üí menos √°rboles complejos
- **reg_alpha/lambda‚Üë:** Regularizaci√≥n L1/L2 m√°s fuerte ‚Üí menos overfitting

**Mejora esperada:**
- Train R¬≤ bajar√° a ~0.85-0.90 (BUENO - menos memorizaci√≥n)
- CV RMSE mejorar√° hacia ~100-120 (m√°s realista)
- Menor gap Train-Val (mejor generalizaci√≥n)

---

### ‚ùå **PROBLEMA 2: RIDGE CON R¬≤ NEGATIVO EN CV**

#### Evidencia:

```python
# Cell 38 output - Ridge CV results
CV R¬≤: -0.0076 ¬± 0.7399  ‚Üê ¬°R¬≤ NEGATIVO! üö©
CV RMSE: 271.95 ¬± 47.32

# Single split
Val R¬≤: 0.5420  ‚Üê Aceptable pero inconsistente con CV
```

**¬øQu√© significa R¬≤ negativo?**
‚Üí El modelo es **PEOR que predecir la media constante**

#### Causa Ra√≠z:

1. **Features no lineales** pero modelo LINEAR
   - Bike demand tiene patrones NO LINEALES (hora pico, clima, interacciones)
   - Ridge espera relaciones lineales simples

2. **Alpha muy bajo** (0.01) ‚Üí Casi no hay regularizaci√≥n

3. **Multicolinealidad** entre los 40 features

#### ‚úÖ Soluci√≥n:

**Ridge NO es apropiado para este problema.** Usar modelos tree-based (RF/XGBoost).

**Si se quiere mantener Ridge (para baseline):**
```python
ridge_params = {
    'alpha': 10.0,  # ‚Üë De 0.01 ‚Üí 10.0 (penaliza colinealidad)
    'max_iter': 10000
}
```

---

## üéØ III. FEATURES FALTANTES - AN√ÅLISIS DE GAPS

### üìã Comparaci√≥n: Key Insights vs Features Implementados

| Feature Sugerido en EDA | ¬øImplementado? | Justificaci√≥n |
|--------------------------|----------------|---------------|
| `atemp` eliminado | ‚úÖ S√ç | Multicolinealidad con temp (r=0.987) |
| `cnt_transformed` (sqrt) | ‚úÖ S√ç | Target transformado |
| Features c√≠clicas (sin/cos) | ‚úÖ S√ç | hr, mnth, weekday |
| `is_weekend` | ‚úÖ S√ç | Patr√≥n diferenciado |
| `is_peak_hour` | ‚úÖ S√ç | Horas 8, 17, 18 |
| `is_commute_window` | ‚úÖ S√ç | 7-9am, 4-7pm |
| `temp_season` | ‚úÖ S√ç | Interacci√≥n clim√°tica |
| `weathersit_season` | ‚úÖ S√ç | Clima √ó estaci√≥n |
| `hr_workingday` | ‚úÖ S√ç | Patr√≥n bimodal |
| `weather_quadrant` | ‚úÖ S√ç | Cuadrantes Temp√óHum |
| Lags [1,24,48,72,168] | ‚úÖ S√ç | Validado por ACF/PACF |
| Rolling means [3,24,72] | ‚úÖ S√ç | Ventanas m√≥viles |
| `cnt_pct_change_1h/24h` | ‚úÖ S√ç | Cambios porcentuales |
| **`casual_share`** | ‚ùå **ELIMINADO** | Data leakage (correcto) |
| **`is_weekend_casual_share`** | ‚ùå **ELIMINADO** | Data leakage (correcto) |

### üîç Features Mencionados en Key Insights pero NO Implementados:

**1. `casual_share` (proporci√≥n de usuarios casuales)**
```python
# Key Insights Section XI.G sugiere:
df_features['casual_lag_1h'] = df_features['casual'].shift(1)
df_features['cnt_lag_1h'] = df_features['cnt'].shift(1)
df_features['casual_share'] = df_features['casual_lag_1h'] / df_features['cnt_lag_1h']
```

**¬øPor qu√© fue eliminado en Cell 62?**
```python
# Cell 62 output:
# "üî¥ casual_share ELIMINADO (prevenci√≥n de data leakage)"
```

**An√°lisis:**
- ‚úÖ **DECISI√ìN CORRECTA**
- `casual` y `registered` son **COMPONENTES** del target: `cnt = casual + registered`
- Aunque se use lag, sigue siendo problem√°tico:
  1. En producci√≥n, puede que NO tengamos acceso a `casual/registered` en tiempo real
  2. Modelo debe ser robusto y no depender de componentes del target
  3. **Principio de simplicidad:** Mejor predecir `cnt` directamente sin descomposici√≥n

**Veredicto:** ‚úÖ Mantener eliminado

---

## üåü IV. FEATURES ADICIONALES SUGERIDOS (BASADO EN EXPERIENCIA)

### üìä Features Propuestos con Justificaci√≥n

#### 1. **Momentum Features (Aceleraci√≥n de Demanda)**

**Concepto:** Capturar si la demanda est√° ACELERANDO o DESACELERANDO

```python
# Aceleraci√≥n de 1h (cambio en el cambio)
df_features['cnt_acceleration_1h'] = (
    df_features['cnt_pct_change_1h'] - 
    df_features['cnt_pct_change_1h'].shift(1)
)

# Aceleraci√≥n de 24h
df_features['cnt_acceleration_24h'] = (
    df_features['cnt_pct_change_24h'] - 
    df_features['cnt_pct_change_24h'].shift(1)
)
```

**Justificaci√≥n:**
- Detecta **tendencias emergentes** (ej: demanda creciendo r√°pidamente antes de un evento)
- √ötil para capturar **patrones de transici√≥n** (ej: paso de valle a pico)

**Evidencia del EDA:**
- Ratio pico/valle = 46x ‚Üí Transiciones abruptas son cr√≠ticas
- Patr√≥n bimodal ‚Üí Momentum puede anticipar picos

---

#### 2. **Features de Volatilidad (Estabilidad de Demanda)**

**Concepto:** Capturar si la demanda es ESTABLE o VOL√ÅTIL

```python
# Desviaci√≥n est√°ndar rolling de 24h (volatilidad)
df_features['cnt_volatility_24h'] = (
    df_features['cnt_transformed']
    .shift(1)
    .rolling(window=24, min_periods=12)
    .std()
)

# Coeficiente de variaci√≥n (normalizado)
df_features['cnt_cv_24h'] = (
    df_features['cnt_volatility_24h'] / 
    df_features['cnt_transformed_roll_mean_24h']
)
```

**Justificaci√≥n:**
- Detecta **d√≠as at√≠picos** o **eventos especiales**
- √ötil para ajustar **bandas de confianza** en predicciones

**Evidencia del EDA:**
- Test de Levene confirm√≥ **heterocedasticidad** (varianza NO constante)
- Festivos y fines de semana tienen mayor variabilidad

---

#### 3. **Features de Contexto Hist√≥rico (¬øMejor o Peor que Ayer?)**

**Concepto:** Comparar demanda actual con promedio hist√≥rico

```python
# Promedio hist√≥rico para misma hora/d√≠a de semana (usando solo train data)
# Calcular en train, aplicar a val/test
historical_avg = (
    train_df
    .groupby(['hr', 'weekday'])['cnt']
    .mean()
    .rename('cnt_historical_avg')
)

# Merge con df_features
df_features = df_features.merge(
    historical_avg,
    on=['hr', 'weekday'],
    how='left'
)

# Feature: desviaci√≥n respecto a promedio hist√≥rico
df_features['cnt_vs_historical'] = (
    df_features['cnt_transformed'] - 
    np.sqrt(df_features['cnt_historical_avg'])
)
```

**Justificaci√≥n:**
- Captura si demanda est√° **por encima/debajo** de lo esperado
- √ötil para detectar **anomal√≠as** y **eventos especiales**

**Evidencia del EDA:**
- Patr√≥n horario es MUY estable (ACF lag 24h = 0.53)
- Patr√≥n semanal significativo (ACF lag 168h = 0.35)

---

#### 4. **Interacciones Clim√°ticas Avanzadas**

**Concepto:** Capturar efectos NO lineales del clima

```python
# Sensaci√≥n t√©rmica cuadr√°tica (efecto parab√≥lico)
df_features['temp_squared'] = df_features['temp'] ** 2

# Interacci√≥n Temp √ó Humedad (√≠ndice de disconfort)
df_features['temp_hum_interaction'] = df_features['temp'] * df_features['hum']

# Interacci√≥n Temp √ó Windspeed (sensaci√≥n de viento fr√≠o)
df_features['temp_wind_interaction'] = df_features['temp'] * df_features['windspeed']

# √çndice de "clima perfecto" (temp √≥ptima ~0.5-0.7, hum baja)
optimal_temp = 0.6  # Normalizado
df_features['is_perfect_weather'] = (
    (df_features['temp'].between(0.5, 0.7)) & 
    (df_features['hum'] < 0.5) &
    (df_features['weathersit'] == 1)
).astype(int)
```

**Justificaci√≥n:**
- **Relaci√≥n parab√≥lica:** Temperatura muy baja O muy alta reduce demanda
- **Efecto multiplicativo:** Humedad alta amplifica efecto negativo de calor

**Evidencia del EDA:**
- Cuadrantes clim√°ticos tienen ratio 2.80x (mejor/peor)
- Correlaci√≥n temp-cnt es moderada (+0.204) pero puede ser NO lineal

---

#### 5. **Features de D√≠a Especial (Beyond Holiday)**

**Concepto:** Capturar d√≠as con comportamiento at√≠pico (NO solo festivos)

```python
# Fin de mes (√∫ltimo 3 d√≠as del mes)
df_features['is_end_of_month'] = (df_features['day'] >= 28).astype(int)

# Primer d√≠a del mes
df_features['is_start_of_month'] = (df_features['day'] == 1).astype(int)

# Temporada universitaria (septiembre-mayo, excluyendo diciembre)
df_features['is_school_season'] = (
    df_features['mnth'].isin([1,2,3,4,5,9,10,11])
).astype(int)

# Verano (junio-agosto)
df_features['is_summer_vacation'] = (
    df_features['mnth'].isin([6,7,8])
).astype(int)
```

**Justificaci√≥n:**
- **Fin/inicio de mes:** Patrones de gasto/salario pueden afectar uso de bicis
- **Temporada escolar:** Estudiantes son usuarios importantes

**Evidencia del EDA:**
- Septiembre tiene la mayor demanda (mes 9)
- Festivos tienen comportamiento diferenciado

---

#### 6. **Features de Rezago Diferenciado por Tipo de D√≠a**

**Concepto:** Lags DIFERENTES para weekdays vs weekends

```python
# Lag condicional: lag_24h solo si mismo tipo de d√≠a
def conditional_lag_24h(row):
    """Usar lag 24h solo si es mismo tipo de d√≠a (weekday vs weekend)"""
    if row['is_weekend'] == 1:
        # Weekend: usar lag 24h de fin de semana anterior
        return row['cnt_transformed_lag_168h']  # 1 semana
    else:
        # Weekday: usar lag 24h del d√≠a anterior
        return row['cnt_transformed_lag_24h']

df_features['cnt_lag_conditional'] = df_features.apply(conditional_lag_24h, axis=1)
```

**Justificaci√≥n:**
- **Lunes NO se parece a Domingo** (fin de semana)
- **S√°bado se parece m√°s a S√°bado anterior** que a Viernes

**Evidencia del EDA:**
- Patr√≥n weekday es bimodal, weekend es uniforme
- Interacci√≥n `hr √ó workingday` es significativa

---

### üìä Resumen de Features Propuestos

| Feature Propuesto | Impacto Esperado | Complejidad | Prioridad |
|-------------------|------------------|-------------|-----------|
| Momentum (aceleraci√≥n) | MEDIO | BAJA | üü° MEDIA |
| Volatilidad (rolling std) | MEDIO-ALTO | BAJA | üü¢ ALTA |
| Contexto hist√≥rico | ALTO | MEDIA | üü¢ ALTA |
| Temp cuadr√°tica | MEDIO | BAJA | üü° MEDIA |
| Interacciones clim√°ticas | MEDIO | BAJA | üü° MEDIA |
| D√≠as especiales | BAJO | BAJA | üî¥ BAJA |
| Lags condicionales | MEDIO | MEDIA | üü° MEDIA |

**Recomendaci√≥n:** Implementar **Volatilidad** y **Contexto hist√≥rico** primero (m√°ximo ROI).

---

## ‚úÖ V. PLAN DE CORRECCIONES - RESUMEN EJECUTIVO

### üî¥ **CR√çTICAS (Hacer AHORA):**

1. **Corregir hiperpar√°metros XGBoost** en `02_modeling.ipynb` (Cell 34)
   ```python
   max_depth: 6 ‚Üí 4
   learning_rate: 0.05 ‚Üí 0.03
   min_child_weight: 3 ‚Üí 5
   gamma: 0.1 ‚Üí 0.5
   reg_alpha: 0.1 ‚Üí 0.5
   reg_lambda: 1.0 ‚Üí 2.0
   ```

2. **Cambiar `min_periods` en rolling windows** en `notebook.ipynb` (Cell 64)
   ```python
   .rolling(window=window, min_periods=1)  
   ‚Üí .rolling(window=window, min_periods=window)
   ```

3. **Actualizar Ridge alpha** en `02_modeling.ipynb` (Cell 22)
   ```python
   alpha: 0.01 ‚Üí 10.0  # Mayor regularizaci√≥n
   ```

### üü° **IMPORTANTES (Hacer PRONTO):**

4. **A√±adir features de volatilidad** en `notebook.ipynb` (nueva celda despu√©s de Cell 64)
   ```python
   df_features['cnt_volatility_24h'] = ...
   df_features['cnt_cv_24h'] = ...
   ```

5. **A√±adir contexto hist√≥rico** en `notebook.ipynb`
   ```python
   cnt_historical_avg = ...
   df_features['cnt_vs_historical'] = ...
   ```

6. **A√±adir interacciones clim√°ticas** en `notebook.ipynb`
   ```python
   df_features['temp_squared'] = ...
   df_features['temp_hum_interaction'] = ...
   ```

### üîµ **OPCIONALES (Considerar para V2):**

7. Momentum features
8. Lags condicionales
9. Features de d√≠as especiales

---

## üéØ VI. CONCLUSIONES Y PR√ìXIMOS PASOS

### ‚úÖ Conclusiones del An√°lisis:

1. **Feature Engineering actual es S√ìLIDO:**
   - ‚úÖ NO hay temporal leakage en lags/rolling means
   - ‚úÖ Transformaci√≥n del target (`sqrt`) es apropiada
   - ‚úÖ Features c√≠clicos, interacciones, e indicadores est√°n bien implementados

2. **Modelado tiene ISSUES CR√çTICOS:**
   - ‚ùå XGBoost tiene overfitting SEVERO (Train R¬≤=0.9998, CV R¬≤=0.7277)
   - ‚ùå Ridge no es apropiado para este problema (R¬≤ negativo en CV)
   - ‚ùå Discrepancia ENORME entre single split y CV (223% en XGBoost)

3. **Oportunidades de Mejora:**
   - üü° Features adicionales (volatilidad, contexto hist√≥rico) pueden mejorar +5-10% MAE
   - üü° Hiperpar√°metros m√°s conservadores mejorar√°n generalizaci√≥n

### üöÄ Acci√≥n Inmediata:

1. **Corregir `02_modeling.ipynb`:**
   - XGBoost hiperpar√°metros m√°s conservadores
   - Ridge alpha m√°s alto
   - Re-ejecutar y verificar que CV RMSE mejora

2. **Mejorar `notebook.ipynb`:**
   - `min_periods=window` en rolling windows
   - A√±adir features de volatilidad y contexto hist√≥rico

3. **Re-evaluar:**
   - Despu√©s de correcciones, XGBoost CV RMSE deber√≠a bajar a ~100-120
   - Gap Train-Val deber√≠a reducirse a <20%

---

**Documento preparado por:** Dr. ML-MLOps Elite Reviewer  
**Pr√≥ximo paso:** Implementar correcciones cr√≠ticas en ambos notebooks

