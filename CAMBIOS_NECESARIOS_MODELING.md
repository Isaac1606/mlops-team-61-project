# üîß CAMBIOS NECESARIOS EN 02_modeling.ipynb

## üìã Resumen Ejecutivo

El notebook `notebook.ipynb` fue actualizado con hallazgos cr√≠ticos del EDA que **requieren cambios obligatorios** en el notebook de modelado (`02_modeling.ipynb`) para mantener consistencia y aprovechar las mejoras implementadas.

---

## üö® CAMBIOS CR√çTICOS OBLIGATORIOS

### 1. ‚ö†Ô∏è **TARGET TRANSFORMADO** (M√ÅS IMPORTANTE)

**Problema Actual:**
```python
# ‚ùå INCORRECTO - Est√° usando target original
y_train = train_df['cnt'].values
y_val = val_df['cnt'].values
y_test = test_df['cnt'].values
```

**Cambio Requerido:**
```python
# ‚úÖ CORRECTO - Usar target transformado
y_train = train_df['cnt_transformed'].values  # sqrt(cnt)
y_val = val_df['cnt_transformed'].values
y_test = test_df['cnt_transformed'].values

print("\n‚ö†Ô∏è IMPORTANTE: Usando target transformado (sqrt)")
print(f"  Target original (cnt): {train_df['cnt'].mean():.2f} ¬± {train_df['cnt'].std():.2f}")
print(f"  Target transformado: {y_train.mean():.2f} ¬± {y_train.std():.2f}")
```

**Justificaci√≥n:**
- An√°lisis experimental en EDA mostr√≥ que `Sqrt(y)` es la mejor transformaci√≥n
- Mejora: +1.97% MAE, +2.34% R¬≤
- Shapiro-Wilk confirm√≥ que target original NO es normal (p < 0.0001)

---

### 2. üîÑ **TRANSFORMACI√ìN INVERSA EN EVALUACI√ìN**

**Problema Actual:**
```python
# ‚ùå INCORRECTO - Evaluando en escala transformada
def evaluate_model(model, X, y_true, dataset_name=""):
    y_pred = model.predict(X)
    mae = mean_absolute_error(y_true, y_pred)  # ‚Üê Escala transformada
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred) * 100
    return {'mae': mae, 'rmse': rmse, 'r2': r2, 'mape': mape}
```

**Cambio Requerido:**
```python
# ‚úÖ CORRECTO - Transformaci√≥n inversa para m√©tricas en escala original
def evaluate_model(model, X, y_true_transformed, dataset_name=""):
    """
    Eval√∫a modelo con m√©tricas en escala ORIGINAL (no transformada)
    
    Args:
        model: Modelo entrenado
        X: Features
        y_true_transformed: Target transformado (sqrt(cnt))
        dataset_name: Nombre del dataset para logging
    
    Returns:
        dict: M√©tricas en escala original
    """
    # Predicci√≥n en escala transformada
    y_pred_transformed = model.predict(X)
    
    # ‚ö†Ô∏è TRANSFORMACI√ìN INVERSA: sqrt(x) ‚Üí x^2
    y_pred_original = y_pred_transformed ** 2
    y_true_original = y_true_transformed ** 2
    
    # Asegurar predicciones no-negativas
    y_pred_original = np.clip(y_pred_original, 0, None)
    
    # Calcular m√©tricas en escala ORIGINAL
    mae = mean_absolute_error(y_true_original, y_pred_original)
    mse = mean_squared_error(y_true_original, y_pred_original)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true_original, y_pred_original)
    mape = mean_absolute_percentage_error(y_true_original, y_pred_original) * 100
    
    print(f"\nüìä Evaluaci√≥n en {dataset_name} (escala ORIGINAL):")
    print(f"  MAE:  {mae:.2f} {'‚úÖ' if mae < 50 else '‚ùå'} (objetivo: < 50)")
    print(f"  RMSE: {rmse:.2f} {'‚úÖ' if rmse < 80 else '‚ùå'} (objetivo: < 80)")
    print(f"  R¬≤:   {r2:.4f} {'‚úÖ' if r2 > 0.7 else '‚ùå'} (objetivo: > 0.7)")
    print(f"  MAPE: {mape:.2f}% {'‚úÖ' if mape < 25 else '‚ùå'} (objetivo: < 25%)")
    
    return {
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'mape': mape,
        'y_pred_original': y_pred_original,  # Para an√°lisis posterior
        'y_true_original': y_true_original
    }
```

**Raz√≥n:**
- Los targets objetivo (MAE < 50, RMSE < 80) est√°n definidos en escala ORIGINAL
- Evaluar en escala transformada dar√≠a m√©tricas no interpretables para negocio

---

### 3. üìä **ACTUALIZAR FEATURES DE DATA LEAKAGE**

**Problema Actual:**
```python
# ‚ùå DESACTUALIZADO - Lags antiguos
leakage_features = [
    'cnt_lag_1h', 'cnt_lag_24h', 'cnt_lag_168h',  # ‚Üê Solo 3 lags
    'cnt_roll_mean_3h', 'cnt_roll_mean_24h',      # ‚Üê Solo 2 rolling
    # ...
    'registered_lag_1h', 'registered_lag_24h', 'registered_lag_168h',  # ‚Üê 3 lags
    'casual_lag_1h', 'casual_lag_24h', 'casual_lag_168h',
]
```

**Cambio Requerido:**
```python
# ‚úÖ ACTUALIZADO - Lags validados por ACF/PACF
leakage_features = [
    # Componentes del target
    'casual_share', 'casual_lag_1h', 'cnt_lag_1h_for_share',
    
    # Lags del target TRANSFORMADO (cnt_transformed = sqrt(cnt))
    'cnt_transformed_lag_1h', 'cnt_transformed_lag_24h', 'cnt_transformed_lag_48h',
    'cnt_transformed_lag_72h', 'cnt_transformed_lag_168h',  # ‚Üê 5 lags (ACF/PACF)
    
    # Rolling means del target transformado
    'cnt_transformed_roll_mean_3h', 'cnt_transformed_roll_mean_24h', 
    'cnt_transformed_roll_mean_72h',  # ‚Üê 3 rolling windows
    
    # Cambios porcentuales del target transformado
    'cnt_pct_change_1h', 'cnt_pct_change_24h',
    
    # Lags de componentes (registered y casual) - ACTUALIZADOS
    'registered_lag_1h', 'registered_lag_24h', 'registered_lag_48h', 
    'registered_lag_72h', 'registered_lag_168h',  # ‚Üê 5 lags
    'registered_roll_mean_3h', 'registered_roll_mean_24h', 'registered_roll_mean_72h',
    
    'casual_lag_1h', 'casual_lag_24h', 'casual_lag_48h', 
    'casual_lag_72h', 'casual_lag_168h',  # ‚Üê 5 lags
    'casual_roll_mean_3h', 'casual_roll_mean_24h', 'casual_roll_mean_72h',
]
```

**Justificaci√≥n:**
- Lags actualizados de `[1, 24, 168]` a `[1, 24, 48, 72, 168]` (validado por ACF/PACF)
- Rolling windows actualizados de `[3, 24]` a `[3, 24, 72]`
- Ahora usamos `cnt_transformed` (no `cnt`)

---

### 4. üéØ **ACTUALIZAR TARGETS OBJETIVO EN M√âTRICAS**

**Problema Actual:**
```python
# ‚ùå M√©tricas objetivo pueden estar desactualizadas
TARGET_METRICS = {
    'MAE': 50,      # ¬øEn qu√© escala?
    'RMSE': 80,     # ¬øEn qu√© escala?
    'R2': 0.7,
    'MAPE': 25
}
```

**Cambio Requerido:**
```python
# ‚úÖ CLARIFICAR - M√©tricas en escala ORIGINAL
TARGET_METRICS = {
    'MAE': 50,      # ‚Üê Escala ORIGINAL (bicicletas/hora)
    'RMSE': 80,     # ‚Üê Escala ORIGINAL (bicicletas/hora)
    'R2': 0.7,      # ‚Üê Invariante a transformaci√≥n
    'MAPE': 25      # ‚Üê Porcentaje, escala ORIGINAL
}

print("="*70)
print("M√âTRICAS OBJETIVO (ESCALA ORIGINAL - NO TRANSFORMADA)")
print("="*70)
print(f"‚ö†Ô∏è IMPORTANTE: Target se predice en escala transformada (sqrt)")
print(f"              M√©tricas se calculan en escala ORIGINAL (cnt)")
print(f"\nObjetivos:")
for metric, target in TARGET_METRICS.items():
    print(f"  ‚Ä¢ {metric}: {'<' if metric not in ['R2'] else '>'} {target}")
print("="*70)
```

---

### 5. üìù **ACTUALIZAR MLflow LOGGING**

**Cambio Requerido:**
```python
# A√±adir metadata de transformaci√≥n
with mlflow.start_run(run_name=f"{model_name}_baseline"):
    # ... training code ...
    
    # ‚úÖ A√ëADIR: Metadata de transformaci√≥n
    mlflow.log_param("target_transformation", "sqrt")
    mlflow.log_param("inverse_transformation", "square")
    mlflow.log_param("lags_used", "[1, 24, 48, 72, 168]")
    mlflow.log_param("rolling_windows", "[3, 24, 72]")
    mlflow.log_param("features_count", len(feature_cols))
    mlflow.log_param("atemp_removed", True)  # Multicolinealidad
    
    # ... rest of logging ...
```

---

## üìä CAMBIOS RECOMENDADOS (NO CR√çTICOS)

### 6. üìà **VISUALIZACI√ìN DE PREDICCIONES**

A√±adir gr√°fico mostrando predicciones en escala original:

```python
def plot_predictions_comparison(y_true, y_pred, dataset_name="Test"):
    """
    Compara predicciones vs valores reales en escala ORIGINAL
    """
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    # Scatter plot
    axes[0].scatter(y_true, y_pred, alpha=0.3, s=10)
    axes[0].plot([y_true.min(), y_true.max()], 
                 [y_true.min(), y_true.max()], 'r--', lw=2)
    axes[0].set_xlabel('Demanda Real (cnt)')
    axes[0].set_ylabel('Demanda Predicha (cnt)')
    axes[0].set_title(f'Predicciones vs Real - {dataset_name}')
    axes[0].grid(True, alpha=0.3)
    
    # Residuos
    residuals = y_true - y_pred
    axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)
    axes[1].axvline(0, color='red', linestyle='--', lw=2)
    axes[1].set_xlabel('Residuos (Real - Predicho)')
    axes[1].set_ylabel('Frecuencia')
    axes[1].set_title('Distribuci√≥n de Residuos')
    axes[1].grid(True, alpha=0.3)
    
    # Serie temporal (primeras 168h)
    n_plot = min(168, len(y_true))
    axes[2].plot(y_true[:n_plot], label='Real', linewidth=1.5, alpha=0.7)
    axes[2].plot(y_pred[:n_plot], label='Predicho', linewidth=1.5, alpha=0.7)
    axes[2].set_xlabel('Hora')
    axes[2].set_ylabel('Demanda (cnt)')
    axes[2].set_title(f'Serie Temporal (primeras {n_plot}h)')
    axes[2].legend()
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # Stats de residuos
    print(f"\nüìä Estad√≠sticas de Residuos:")
    print(f"  Mean: {residuals.mean():.2f}")
    print(f"  Std: {residuals.std():.2f}")
    print(f"  Min: {residuals.min():.2f}")
    print(f"  Max: {residuals.max():.2f}")
```

---

### 7. üéØ **AN√ÅLISIS POR SEGMENTOS**

Evaluar performance en diferentes rangos de demanda:

```python
def evaluate_by_segments(y_true, y_pred):
    """
    Eval√∫a performance por segmentos de demanda (seg√∫n ML Canvas)
    """
    # Definir segmentos (seg√∫n ML Canvas)
    low_mask = y_true < 1000
    medium_mask = (y_true >= 1000) & (y_true <= 7000)
    high_mask = y_true > 7000
    
    segments = {
        'Baja (<1K)': low_mask,
        'Media (1K-7K)': medium_mask,
        'Alta (>7K)': high_mask
    }
    
    print("\n" + "="*70)
    print("EVALUACI√ìN POR SEGMENTOS DE DEMANDA")
    print("="*70)
    
    for segment_name, mask in segments.items():
        n_samples = mask.sum()
        if n_samples == 0:
            print(f"\n{segment_name}: Sin muestras")
            continue
            
        y_true_seg = y_true[mask]
        y_pred_seg = y_pred[mask]
        
        mae = mean_absolute_error(y_true_seg, y_pred_seg)
        rmse = np.sqrt(mean_squared_error(y_true_seg, y_pred_seg))
        r2 = r2_score(y_true_seg, y_pred_seg)
        mape = mean_absolute_percentage_error(y_true_seg, y_pred_seg) * 100
        
        print(f"\n{segment_name}: {n_samples} muestras ({n_samples/len(y_true)*100:.1f}%)")
        print(f"  MAE:  {mae:.2f}")
        print(f"  RMSE: {rmse:.2f}")
        print(f"  R¬≤:   {r2:.4f}")
        print(f"  MAPE: {mape:.2f}%")
    
    print("="*70)
```

---

## üîç CHECKLIST DE VERIFICACI√ìN

Antes de ejecutar el notebook de modelado, verificar:

- [ ] **Target:** Usar `cnt_transformed` (no `cnt`)
- [ ] **Leakage Features:** Actualizar lista con lags `[1, 24, 48, 72, 168]`
- [ ] **Rolling Windows:** Actualizar a `[3, 24, 72]`
- [ ] **Transformaci√≥n Inversa:** Aplicar `y_pred^2` antes de evaluar m√©tricas
- [ ] **Evaluaci√≥n:** M√©tricas en escala ORIGINAL (no transformada)
- [ ] **MLflow Params:** Incluir metadata de transformaci√≥n
- [ ] **Visualizaciones:** Mostrar predicciones en escala original
- [ ] **Features:** Verificar que `atemp` NO est√© en features (eliminada por multicolinealidad)
- [ ] **Documentaci√≥n:** Comentarios claros sobre transformaci√≥n en todo el c√≥digo

---

## üìÇ ARCHIVOS AFECTADOS

### Archivos que YA est√°n actualizados:
‚úÖ `notebook.ipynb` - EDA y Feature Engineering completo con transformaci√≥n

### Archivos que NECESITAN actualizaci√≥n:
‚ùå `02_modeling.ipynb` - Requiere TODOS los cambios listados arriba

### Archivos que pueden requerir ajustes menores:
‚ö†Ô∏è Scripts en `src/models/` (si existen) - Verificar transformaci√≥n del target
‚ö†Ô∏è Scripts de predicci√≥n/inferencia - Asegurar transformaci√≥n inversa

---

## üöÄ IMPACTO ESPERADO

Con estos cambios implementados:

1. **Mejora en m√©tricas:** +1.97% MAE, +2.34% R¬≤ (validado experimentalmente)
2. **Reducci√≥n de sesgo:** Target transformado reduce sesgo de 15.09 a ~2-3
3. **Mejor convergencia:** Modelos convergen m√°s r√°pido con target normalizado
4. **Interpretabilidad:** M√©tricas en escala original son directamente interpretables
5. **Consistencia:** Notebooks alineados con hallazgos del EDA

---

## ‚ö†Ô∏è ADVERTENCIAS

1. **NO** mezclar escalas: Entrenar en escala transformada, evaluar en escala original
2. **SIEMPRE** aplicar transformaci√≥n inversa antes de calcular m√©tricas finales
3. **VERIFICAR** que features de leakage est√©n correctamente excluidas
4. **DOCUMENTAR** claramente en qu√© escala se est√° trabajando en cada paso
5. **GUARDAR** tanto modelo como metadata de transformaci√≥n para producci√≥n

---

## üìû PR√ìXIMOS PASOS

1. ‚úÖ Leer este documento completo
2. ‚úÖ Hacer backup del notebook actual de modelado
3. ‚úÖ Implementar cambios cr√≠ticos (1-5) en orden
4. ‚úÖ Implementar cambios recomendados (6-7) si tiempo permite
5. ‚úÖ Ejecutar notebook completo y verificar m√©tricas
6. ‚úÖ Comparar resultados antes/despu√©s de transformaci√≥n
7. ‚úÖ Documentar mejoras en presentaci√≥n final

---

**Fecha:** 2025-10-12  
**Basado en:** Hallazgos del EDA exhaustivo con an√°lisis ACF/PACF y evaluaci√≥n experimental de transformaciones

