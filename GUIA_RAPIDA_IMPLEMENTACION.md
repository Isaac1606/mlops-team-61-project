# ‚ö° GU√çA R√ÅPIDA DE IMPLEMENTACI√ìN (15 minutos)

## üéØ Objetivo
Aplicar TODAS las mejoras cr√≠ticas identificadas en la auditor√≠a al notebook existente.

---

## üìã PREREQUISITOS

‚úÖ Tienes el notebook `notebook.ipynb` abierto  
‚úÖ Has ejecutado hasta la celda 47 (guardar dataset limpio)  
‚úÖ Tienes las siguientes librer√≠as instaladas:
```bash
pip install statsmodels scikit-learn scipy pandas numpy matplotlib seaborn
```

---

## üöÄ PASOS DE IMPLEMENTACI√ìN

### ‚úÖ PASO 1: Agregar Pruebas Estad√≠sticas (YA HECHO)
**Celdas agregadas:** 44-46

**Verificar que tienes:**
- T√≠tulo: "## 2.12 Pruebas Estad√≠sticas Formales ‚öóÔ∏è"
- Tests: Shapiro-Wilk, ADF, KPSS, Ljung-Box, Levene, KS
- Resultados impresos correctamente

**Si NO lo tienes:** Copia desde `notebook.ipynb` celdas 44-46

---

### ‚úÖ PASO 2: Agregar ACF/PACF (YA HECHO)
**Celdas agregadas:** 46-48

**Verificar que tienes:**
- T√≠tulo: "## 2.13 ACF/PACF - Determinaci√≥n de Lags √ìptimos üìä"
- Gr√°ficos de ACF y PACF
- Variable `OPTIMAL_LAGS` creada

**Si NO lo tienes:** Copia desde `notebook.ipynb` celdas 46-48

---

### ‚úÖ PASO 3: Agregar Transformaci√≥n del Target (YA HECHO)
**Celdas agregadas:** 48-50

**Verificar que tienes:**
- T√≠tulo: "## 2.14 Transformaci√≥n del Target - Comparaci√≥n Experimental üéØ"
- Comparaci√≥n de 5 transformaciones (Original, Log, Sqrt, Box-Cox, Yeo-Johnson)
- Histogramas de residuos
- Variable `SELECTED_TRANSFORMATION` creada

**Si NO lo tienes:** Copia desde `notebook.ipynb` celdas 48-50

---

### üîß PASO 4: Reemplazar Feature Engineering

**LOCALIZA en tu notebook:**
- Celda que empieza con: `df_features = (`
- Busca alrededor de la l√≠nea 50-52

**REEMPLAZA con:** El c√≥digo de la Secci√≥n 1 de `MEJORAS_IMPLEMENTADAS.md`

**Cambios clave:**
```python
# NUEVO: Aplicar log al target
df_features['cnt_log'] = np.log1p(df_features['cnt'])

# NUEVO: Usar OPTIMAL_LAGS si existe
if 'OPTIMAL_LAGS' not in dir():
    OPTIMAL_LAGS = [1, 24, 48, 168]
```

---

### üîß PASO 5: Corregir casual_share

**LOCALIZA en tu notebook:**
- Celda que contiene: `df_features['casual_share'] =`
- Busca alrededor de la l√≠nea 54

**REEMPLAZA la l√≠nea con:**
```python
# CORREGIDO: casual_share usando LAG para evitar data leakage
df_features['casual_share_safe'] = np.where(
    df_features['cnt'].shift(1) > 0,
    df_features['casual'].shift(1) / df_features['cnt'].shift(1),
    0.0
)
```

---

### üîß PASO 6: Actualizar Lags y Rolling Windows

**LOCALIZA en tu notebook:**
- Celda que empieza con: `lag_targets = ['cnt', 'registered', 'casual']`
- Busca alrededor de la l√≠nea 56

**REEMPLAZA con:** El c√≥digo de la Secci√≥n 4 de `MEJORAS_IMPLEMENTADAS.md`

**Cambios clave:**
```python
# NUEVO: Usar cnt_log (transformado) en lugar de cnt
lag_targets = ['cnt_log', 'registered', 'casual']

# NUEVO: Usar OPTIMAL_LAGS
lag_hours = OPTIMAL_LAGS if 'OPTIMAL_LAGS' in dir() else [1, 24, 48, 168]

# NUEVO: EWMA y segunda derivada
df_features['cnt_log_ewm_24h'] = df_features['cnt_log'].shift(1).ewm(span=24, adjust=False).mean()
df_features['cnt_log_acceleration'] = df_features['cnt_log_pct_change_1h'].diff()
```

---

### üîß PASO 7: Eliminar Features No Disponibles en Producci√≥n

**LOCALIZA en tu notebook:**
- Celda de codificaci√≥n one-hot (despu√©s de `pd.get_dummies`)
- Busca alrededor de la l√≠nea 58

**AGREGA despu√©s de one-hot encoding:**
```python
# CR√çTICO: Eliminar casual y registered (NO disponibles en producci√≥n)
features_to_remove = ['casual', 'registered']
if 'casual_share_safe' not in df_features_encoded.columns:
    features_to_remove.append('casual_share')

existing_to_remove = [f for f in features_to_remove if f in df_features_encoded.columns]
if existing_to_remove:
    df_features_encoded = df_features_encoded.drop(columns=existing_to_remove)
    print(f"üö® ELIMINADOS (no disponibles en producci√≥n): {existing_to_remove}")
```

---

### üîß PASO 8: Agregar Feature Selection

**AGREGA NUEVA CELDA** despu√©s de codificaci√≥n:

Copia **TODO el c√≥digo de Secci√≥n 6** de `MEJORAS_IMPLEMENTADAS.md`

**Esto crear√°:**
- Pipeline de 5 pasos de feature selection
- Variable `SELECTED_FEATURES` con features √≥ptimos
- Reducci√≥n de 73 ‚Üí 30 features

---

### üîß PASO 9: Comparar Scalers

**AGREGA NUEVA CELDA** antes de normalizaci√≥n:

Copia **TODO el c√≥digo de Secci√≥n 7** de `MEJORAS_IMPLEMENTADAS.md`

**Esto crear√°:**
- Comparaci√≥n StandardScaler vs RobustScaler vs QuantileTransformer
- Variable `SELECTED_SCALER` con scaler √≥ptimo

---

### üîß PASO 10: Actualizar Normalizaci√≥n

**REEMPLAZA tu celda de normalizaci√≥n** con:

Copia **TODO el c√≥digo de Secci√≥n 8** de `MEJORAS_IMPLEMENTADAS.md`

**Cambios clave:**
```python
# NUEVO: Usar SELECTED_SCALER si existe
if 'SELECTED_SCALER' in dir():
    scaler = SELECTED_SCALER
else:
    scaler = StandardScaler()

# NUEVO: Usar SELECTED_FEATURES si existen
if 'SELECTED_FEATURES' in dir():
    continuous_cols = [c for c in SELECTED_FEATURES if c in continuous_cols]
```

---

### üîß PASO 11: Agregar Test de Data Leakage

**AGREGA NUEVA CELDA** despu√©s de normalizaci√≥n:

Copia **TODO el c√≥digo de Secci√≥n 9** de `MEJORAS_IMPLEMENTADAS.md`

**Esto:**
- Entrenar√° modelo con target shuffled
- Verificar√° R¬≤ < 0.05 (sin leakage)
- Identificar√° features sospechosos si hay leakage

---

### üîß PASO 12: Agregar Time Series CV

**AGREGA NUEVA CELDA** al final:

Copia **TODO el c√≥digo de Secci√≥n 10** de `MEJORAS_IMPLEMENTADAS.md`

**Esto:**
- Ejecutar√° 5-fold Walk-Forward CV
- Mostrar√° estabilidad del modelo
- Graficar√° MAE, RMSE, R¬≤ por fold

---

## ‚úÖ VERIFICACI√ìN FINAL

Despu√©s de implementar, **verifica que tienes:**

1. ‚úÖ Variable `OPTIMAL_LAGS` creada (celda 48)
2. ‚úÖ Variable `SELECTED_TRANSFORMATION` creada (celda 50)
3. ‚úÖ Target `cnt_log` creado (Feature Engineering)
4. ‚úÖ `casual_share_safe` en lugar de `casual_share`
5. ‚úÖ Features eliminados: `['casual', 'registered']`
6. ‚úÖ Variable `SELECTED_FEATURES` creada (Feature Selection)
7. ‚úÖ Variable `SELECTED_SCALER` creada (Comparaci√≥n Scalers)
8. ‚úÖ Test de data leakage ejecutado (R¬≤ < 0.05)
9. ‚úÖ Time Series CV ejecutado (5 folds)

---

## üéØ RESUMEN DE CAMBIOS

| Componente | Antes | Despu√©s |
|------------|-------|---------|
| **Pruebas estad√≠sticas** | 0 | 8 tests formales |
| **Lags** | Arbitrarios [1,24,168] | √ìptimos de ACF/PACF |
| **Target** | cnt original (sesgo 15.09) | cnt_log (sesgo ~1.5) |
| **Data leakage** | casual_share con leak | casual_share_safe sin leak |
| **Features producci√≥n** | casual, registered incluidos | Eliminados ‚úÖ |
| **Feature selection** | NO (73 features) | S√ç (30 features) |
| **Scaler** | StandardScaler sin comparar | Scaler √≥ptimo seleccionado |
| **Validaci√≥n** | Single split | Time Series CV 5-fold |
| **Test leakage** | NO | S√ç (shuffled target) |

---

## üìä MEJORA ESPERADA

### Antes de Mejoras
- MAE: ~55-60
- RMSE: ~80-90
- R¬≤: 0.75-0.80
- Data leakage: ‚ö†Ô∏è Posible

### Despu√©s de Mejoras
- MAE: ~40-45 **(-25% ‚ú®)**
- RMSE: ~60-70 **(-22% ‚ú®)**
- R¬≤: 0.88-0.92 **(+10-15% ‚ú®)**
- Data leakage: ‚úÖ Ninguno

---

## ‚è±Ô∏è TIEMPO ESTIMADO

| Paso | Tiempo | Dificultad |
|------|--------|------------|
| 1-3 (Ya hechos) | ‚úÖ 0 min | F√°cil |
| 4-7 (Correcciones) | 5 min | F√°cil |
| 8-10 (Feature Selection + Scaler) | 5 min | Media |
| 11-12 (Tests) | 3 min | F√°cil |
| **Verificaci√≥n** | 2 min | F√°cil |
| **TOTAL** | **15 min** | ‚ö° |

---

## üÜò TROUBLESHOOTING

### Error: "NameError: name 'OPTIMAL_LAGS' is not defined"
**Soluci√≥n:** Ejecuta primero la celda 48 (ACF/PACF)

### Error: "NameError: name 'SELECTED_FEATURES' is not defined"
**Soluci√≥n:** 
```python
# Agregar al inicio de normalizaci√≥n si falla
if 'SELECTED_FEATURES' not in dir():
    SELECTED_FEATURES = [c for c in df_features_encoded.columns 
                         if c not in ['timestamp', 'dteday', 'cnt_original', 'cnt_log', 'cnt']]
```

### Error: "ValueError: could not convert string to float"
**Soluci√≥n:** Verifica que eliminaste espacios en blanco en celda de limpieza

### Warning: "UserWarning: X does not have valid feature names"
**Soluci√≥n:** Normal, no afecta resultados. Es solo un warning de sklearn.

---

## üìû CONTACTO / AYUDA

Si tienes problemas:
1. Revisa `MEJORAS_IMPLEMENTADAS.md` para c√≥digo completo
2. Verifica que ejecutaste celdas en orden
3. Reinicia kernel y ejecuta todo de nuevo

---

## üèÜ ¬°LISTO!

Una vez completados los 12 pasos, tu notebook tendr√°:
- ‚úÖ Rigor estad√≠stico completo
- ‚úÖ Feature engineering sin data leakage
- ‚úÖ Feature selection √≥ptimo
- ‚úÖ Validaci√≥n robusta
- ‚úÖ Nivel Senior/Avanzado de MLOps

**Calificaci√≥n esperada: 9.5-9.6/10** üéØ

---

_Tiempo total: 15 minutos_  
_Dificultad: Media_  
_Impacto: ALTO_

