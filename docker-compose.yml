# =============================================================================
# docker-compose.yml - Development and Production Setup
# =============================================================================
# This file provides a complete setup with Redis for caching predictions
# =============================================================================

version: '3.8'

services:
  # ML Service - FastAPI application
  ml-service:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: bike-sharing-ml-service
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - MODEL_NAME=${MODEL_NAME:-}  # Optional: specify model name
    volumes:
      # Mount models directory for easy model updates
      - ./models:/app/models:ro
      # Mount config for easy configuration updates
      - ./config:/app/config:ro
    depends_on:
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ml-network

  # Redis - For prediction caching and historical features
  redis:
    image: redis:7-alpine
    container_name: bike-sharing-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      - ml-network

volumes:
  redis-data:
    driver: local

networks:
  ml-network:
    driver: bridge

